{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "machine_shape": "hm",
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4gFyS2uUITbI",
        "outputId": "0a341991-0f49-4d93-a865-a895351faeeb"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--2024-09-23 13:50:42--  https://raw.githubusercontent.com/mrdbourke/tensorflow-deep-learning/main/extras/helper_functions.py\n",
            "Resolving raw.githubusercontent.com (raw.githubusercontent.com)... 185.199.108.133, 185.199.109.133, 185.199.110.133, ...\n",
            "Connecting to raw.githubusercontent.com (raw.githubusercontent.com)|185.199.108.133|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 10246 (10K) [text/plain]\n",
            "Saving to: ‘helper_functions.py’\n",
            "\n",
            "\rhelper_functions.py   0%[                    ]       0  --.-KB/s               \rhelper_functions.py 100%[===================>]  10.01K  --.-KB/s    in 0s      \n",
            "\n",
            "2024-09-23 13:50:42 (132 MB/s) - ‘helper_functions.py’ saved [10246/10246]\n",
            "\n"
          ]
        }
      ],
      "source": [
        "!wget https://raw.githubusercontent.com/mrdbourke/tensorflow-deep-learning/main/extras/helper_functions.py"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#import helper functions we're going to use in this notebook\n",
        "\n",
        "from helper_functions import create_tensorboard_callback, plot_loss_curves, unzip_data, walk_through_dir"
      ],
      "metadata": {
        "id": "uMu8A0dcJg_j"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "\n",
        "for dirpath, dirnames, filenames in os.walk(\"/content/drive/MyDrive/Tez Dosyaları/part 1\"):\n",
        "  print(f\"There are {len(dirnames)} directories and {len(filenames)} images in '{dirpath}'.\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "c4HcZVYOJjDy",
        "outputId": "dbb9067a-da91-48b0-aa34-ba28eaa9eee9"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "There are 2 directories and 0 images in '/content/drive/MyDrive/Tez Dosyaları/part 1'.\n",
            "There are 2 directories and 0 images in '/content/drive/MyDrive/Tez Dosyaları/part 1/Test'.\n",
            "There are 0 directories and 17 images in '/content/drive/MyDrive/Tez Dosyaları/part 1/Test/Benign'.\n",
            "There are 0 directories and 56 images in '/content/drive/MyDrive/Tez Dosyaları/part 1/Test/Malignant'.\n",
            "There are 2 directories and 0 images in '/content/drive/MyDrive/Tez Dosyaları/part 1/Train'.\n",
            "There are 0 directories and 222 images in '/content/drive/MyDrive/Tez Dosyaları/part 1/Train/Malignant'.\n",
            "There are 0 directories and 71 images in '/content/drive/MyDrive/Tez Dosyaları/part 1/Train/Benign'.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "train_dir = \"/content/drive/MyDrive/Tez Dosyaları/part 1/Train\"\n",
        "test_dir = \"/content/drive/MyDrive/Tez Dosyaları/part 1/Test\""
      ],
      "metadata": {
        "id": "ULpbbYmmJpQa"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import tensorflow as tf\n",
        "BATCH_SIZE = 32\n",
        "IMG_SIZE = (224, 224)\n",
        "train_data= tf.keras.preprocessing.image_dataset_from_directory(train_dir,\n",
        "                                                          label_mode=\"binary\",\n",
        "                                                          batch_size=BATCH_SIZE,\n",
        "                                                          image_size=IMG_SIZE)\n",
        "\n",
        "test_data = tf.keras.preprocessing.image_dataset_from_directory(test_dir,\n",
        "                                                          label_mode=\"binary\",\n",
        "                                                          batch_size=BATCH_SIZE,\n",
        "                                                          image_size=IMG_SIZE)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yG6kaW3HJuYh",
        "outputId": "c8cfc74f-501f-4218-ef9a-a6386c28ed47"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Found 293 files belonging to 2 classes.\n",
            "Found 73 files belonging to 2 classes.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "train_data.class_names"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GH6BdouQJwVp",
        "outputId": "9eab86e0-499e-4636-da95-6f58bb851e46"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['Benign', 'Malignant']"
            ]
          },
          "metadata": {},
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
        "from tensorflow.keras.preprocessing.image import img_to_array\n",
        "from tensorflow.keras.preprocessing.image import load_img\n",
        "import numpy as np\n",
        "import random\n",
        "import math\n",
        "import csv\n",
        "import cv2\n",
        "import os"
      ],
      "metadata": {
        "id": "lUG2l2YjJx5p"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "image_width = 224\n",
        "image_height = 224\n",
        "classes = ['Benign', 'Malignant']\n",
        "datagen = ImageDataGenerator(\n",
        "    rescale=1.0/255,\n",
        "    rotation_range=40,\n",
        "    width_shift_range=0.2,\n",
        "    height_shift_range=0.2,\n",
        "    shear_range=0.2,\n",
        "    zoom_range=0.2,\n",
        "    horizontal_flip=True,\n",
        "    fill_mode='nearest'\n",
        ")\n",
        "\n",
        "# Resimleri yüklemek için flow_from_directory kullanın\n",
        "train_generator = datagen.flow_from_directory(\n",
        "    directory=\"/content/drive/MyDrive/Tez Dosyaları/part 1/Train\",\n",
        "    target_size=(image_width, image_height),\n",
        "    batch_size=32,\n",
        "    class_mode='categorical',\n",
        "    subset='training'\n",
        ")\n",
        "\n",
        "# Her sınıf için resimleri ayrı ayrı arttırın\n",
        "for cls in classes:\n",
        "    # Sınıfın resimlerini yüklemek için flow_from_directory kullanın\n",
        "    cls_generator = datagen.flow_from_directory(\n",
        "        directory=\"/content/drive/MyDrive/Tez Dosyaları/part 1/Train\",\n",
        "        target_size=(image_width, image_height),\n",
        "        batch_size=32,\n",
        "        class_mode='categorical',\n",
        "        subset='training',\n",
        "        classes=[cls]\n",
        "    )\n",
        "\n",
        "    # Resimleri arttırın ve kaydedin\n",
        "    i = 0\n",
        "    for batch in cls_generator:\n",
        "        images, labels = batch\n",
        "        for image in images:\n",
        "            # Resmi kaydetmek için imwrite kullanın\n",
        "            cv2.imwrite(os.path.join(\"/content/drive/MyDrive/Tez Dosyaları/part 1/Train\", cls, f\"augmented_{i}.jpg\"), image * 255)\n",
        "            i += 1\n",
        "            if i >= 3000:  # Maksimum resim sayısına ulaşıldığında döngüyü durdur\n",
        "                break\n",
        "        else:\n",
        "            continue\n",
        "        break"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9203ZUFHJzSp",
        "outputId": "282b3340-6eeb-4b39-d153-2ace6791dc65"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Found 293 images belonging to 2 classes.\n",
            "Found 71 images belonging to 1 classes.\n",
            "Found 222 images belonging to 1 classes.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Load the augmented images for the malignant class\n",
        "augmented_images = os.listdir(\"/content/drive/MyDrive/Tez Dosyaları/part 1/Train/Malignant\")\n",
        "\n",
        "# Count the number of augmented images\n",
        "num_malignant_images = len(augmented_images)\n",
        "\n",
        "# Print the number of malignant images\n",
        "print(\"Number of malignant images:\", num_malignant_images)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "h0cVYz-OJ74y",
        "outputId": "76666551-edbd-4c06-c1c8-ca4c0b22e09a"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Number of malignant images: 3222\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "augmented_images3 = os.listdir(\"/content/drive/MyDrive/Tez Dosyaları/part 1/Train/Benign\")\n",
        "\n",
        "# Count the number of augmented images\n",
        "num_benign_images = len(augmented_images3)\n",
        "\n",
        "# Print the number of malignant images\n",
        "print(\"Number of benign images:\", num_benign_images)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "19MdJKQxKCJx",
        "outputId": "ea026629-17d8-4623-a07f-9930970e6b6d"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Number of benign images: 3071\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import tensorflow as tf\n",
        "BATCH_SIZE = 32\n",
        "IMG_SIZE = (224, 224)\n",
        "train_data= tf.keras.preprocessing.image_dataset_from_directory(train_dir,\n",
        "                                                          label_mode=\"binary\",\n",
        "                                                          batch_size=BATCH_SIZE,\n",
        "                                                          image_size=IMG_SIZE)\n",
        "\n",
        "test_data = tf.keras.preprocessing.image_dataset_from_directory(test_dir,\n",
        "                                                          label_mode=\"binary\",\n",
        "                                                          batch_size=BATCH_SIZE,\n",
        "                                                          image_size=IMG_SIZE)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UibQS-PSKGQp",
        "outputId": "c7822317-95e8-42d0-8657-64c91e21b60e"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Found 6293 files belonging to 2 classes.\n",
            "Found 73 files belonging to 2 classes.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# 1.  create base model with tf.keras.applications\n",
        "base_model = tf.keras.applications.VGG19(include_top=False)\n",
        "\n",
        "# 2. Freeze the base model\n",
        "base_model.trainable = False\n",
        "\n",
        "# 3. create inputs into our model\n",
        "inputs = tf.keras.layers.Input(shape=(224, 224, 3), name=\"input_layer\")\n",
        "\n",
        "# 4. if using ResNet50V2 you will need to normalize inputs\n",
        "# x = tf.keras.layers.experimental.preprocessing.Rescaling(1./255)(inputs)\n",
        "\n",
        "# 5. pass the inputs to the base_model\n",
        "x = base_model(inputs)\n",
        "print(f\"Shape after passing inputs through base model: {x.shape}\")\n",
        "\n",
        "# 6. average pool the outputs of the base model (aggregate all the most important information, reduce number of computations)\n",
        "x = tf.keras.layers.GlobalAveragePooling2D(name=\"global_average_pooling_layer\")(x)\n",
        "print(f\"Shape after GlobalAveragePooling2D: {x.shape}\")\n",
        "\n",
        "# 7. create the output activation layer\n",
        "outputs = tf.keras.layers.Dense(1, activation=\"sigmoid\", name=\"output_layer\")(x)\n",
        "model_0 = tf.keras.Model(inputs, outputs)\n",
        "\n",
        "# 8. compile the model\n",
        "model_0.compile(loss=\"binary_crossentropy\",\n",
        "                optimizer=tf.keras.optimizers.Adam(),\n",
        "                metrics=[\"accuracy\"])\n",
        "\n",
        "# 9. fit the model\n",
        "history_0 = model_0.fit(train_data,\n",
        "                        epochs=40,\n",
        "                        steps_per_epoch=len(train_data),\n",
        "                        validation_data=None,  # validation'ı kapat\n",
        "                        callbacks=[create_tensorboard_callback(dir_name=\"transfer_learning\",\n",
        "                                                              experiment_name=\"10_percent_feature_extraction\")])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "aHspNjQ9KII5",
        "outputId": "1cd0e29e-3200-42b0-cdb7-c365fe46e028"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading data from https://storage.googleapis.com/tensorflow/keras-applications/vgg19/vgg19_weights_tf_dim_ordering_tf_kernels_notop.h5\n",
            "\u001b[1m80134624/80134624\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 0us/step\n",
            "Shape after passing inputs through base model: (None, 7, 7, 512)\n",
            "Shape after GlobalAveragePooling2D: (None, 512)\n",
            "Saving TensorBoard log files to: transfer_learning/10_percent_feature_extraction/20240923-135741\n",
            "Epoch 1/40\n",
            "\u001b[1m197/197\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m68s\u001b[0m 267ms/step - accuracy: 0.5499 - loss: 0.8381\n",
            "Epoch 2/40\n",
            "\u001b[1m197/197\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 49us/step - accuracy: 0.0000e+00 - loss: 0.0000e+00\n",
            "Epoch 3/40\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/lib/python3.10/contextlib.py:153: UserWarning: Your input ran out of data; interrupting training. Make sure that your dataset or generator can generate at least `steps_per_epoch * epochs` batches. You may need to use the `.repeat()` function when building your dataset.\n",
            "  self.gen.throw(typ, value, traceback)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1m197/197\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m29s\u001b[0m 149ms/step - accuracy: 0.6550 - loss: 0.6147\n",
            "Epoch 4/40\n",
            "\u001b[1m197/197\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 35us/step - accuracy: 0.0000e+00 - loss: 0.0000e+00\n",
            "Epoch 5/40\n",
            "\u001b[1m197/197\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m29s\u001b[0m 146ms/step - accuracy: 0.7187 - loss: 0.5405\n",
            "Epoch 6/40\n",
            "\u001b[1m197/197\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 34us/step - accuracy: 0.0000e+00 - loss: 0.0000e+00\n",
            "Epoch 7/40\n",
            "\u001b[1m197/197\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m30s\u001b[0m 150ms/step - accuracy: 0.7445 - loss: 0.5061\n",
            "Epoch 8/40\n",
            "\u001b[1m197/197\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 35us/step - accuracy: 0.0000e+00 - loss: 0.0000e+00\n",
            "Epoch 9/40\n",
            "\u001b[1m197/197\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m30s\u001b[0m 151ms/step - accuracy: 0.7652 - loss: 0.4776\n",
            "Epoch 10/40\n",
            "\u001b[1m197/197\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 36us/step - accuracy: 0.0000e+00 - loss: 0.0000e+00\n",
            "Epoch 11/40\n",
            "\u001b[1m197/197\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m29s\u001b[0m 148ms/step - accuracy: 0.7740 - loss: 0.4623\n",
            "Epoch 12/40\n",
            "\u001b[1m197/197\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 33us/step - accuracy: 0.0000e+00 - loss: 0.0000e+00\n",
            "Epoch 13/40\n",
            "\u001b[1m197/197\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m29s\u001b[0m 149ms/step - accuracy: 0.7876 - loss: 0.4471\n",
            "Epoch 14/40\n",
            "\u001b[1m197/197\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 35us/step - accuracy: 0.0000e+00 - loss: 0.0000e+00\n",
            "Epoch 15/40\n",
            "\u001b[1m197/197\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m30s\u001b[0m 150ms/step - accuracy: 0.7910 - loss: 0.4335\n",
            "Epoch 16/40\n",
            "\u001b[1m197/197\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 35us/step - accuracy: 0.0000e+00 - loss: 0.0000e+00\n",
            "Epoch 17/40\n",
            "\u001b[1m197/197\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m30s\u001b[0m 150ms/step - accuracy: 0.7929 - loss: 0.4314\n",
            "Epoch 18/40\n",
            "\u001b[1m197/197\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 34us/step - accuracy: 0.0000e+00 - loss: 0.0000e+00\n",
            "Epoch 19/40\n",
            "\u001b[1m197/197\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m29s\u001b[0m 149ms/step - accuracy: 0.8019 - loss: 0.4202\n",
            "Epoch 20/40\n",
            "\u001b[1m197/197\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 35us/step - accuracy: 0.0000e+00 - loss: 0.0000e+00\n",
            "Epoch 21/40\n",
            "\u001b[1m197/197\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m29s\u001b[0m 149ms/step - accuracy: 0.8069 - loss: 0.4141\n",
            "Epoch 22/40\n",
            "\u001b[1m197/197\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 46us/step - accuracy: 0.0000e+00 - loss: 0.0000e+00\n",
            "Epoch 23/40\n",
            "\u001b[1m197/197\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m29s\u001b[0m 149ms/step - accuracy: 0.8057 - loss: 0.4111\n",
            "Epoch 24/40\n",
            "\u001b[1m197/197\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 39us/step - accuracy: 0.0000e+00 - loss: 0.0000e+00\n",
            "Epoch 25/40\n",
            "\u001b[1m197/197\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m29s\u001b[0m 149ms/step - accuracy: 0.8100 - loss: 0.4056\n",
            "Epoch 26/40\n",
            "\u001b[1m197/197\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 33us/step - accuracy: 0.0000e+00 - loss: 0.0000e+00\n",
            "Epoch 27/40\n",
            "\u001b[1m197/197\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m29s\u001b[0m 149ms/step - accuracy: 0.8106 - loss: 0.4003\n",
            "Epoch 28/40\n",
            "\u001b[1m197/197\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 35us/step - accuracy: 0.0000e+00 - loss: 0.0000e+00\n",
            "Epoch 29/40\n",
            "\u001b[1m197/197\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m29s\u001b[0m 149ms/step - accuracy: 0.8153 - loss: 0.3938\n",
            "Epoch 30/40\n",
            "\u001b[1m197/197\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 35us/step - accuracy: 0.0000e+00 - loss: 0.0000e+00\n",
            "Epoch 31/40\n",
            "\u001b[1m197/197\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m29s\u001b[0m 149ms/step - accuracy: 0.8197 - loss: 0.3886\n",
            "Epoch 32/40\n",
            "\u001b[1m197/197\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 38us/step - accuracy: 0.0000e+00 - loss: 0.0000e+00\n",
            "Epoch 33/40\n",
            "\u001b[1m197/197\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m30s\u001b[0m 149ms/step - accuracy: 0.8170 - loss: 0.3891\n",
            "Epoch 34/40\n",
            "\u001b[1m197/197\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 36us/step - accuracy: 0.0000e+00 - loss: 0.0000e+00\n",
            "Epoch 35/40\n",
            "\u001b[1m197/197\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m29s\u001b[0m 149ms/step - accuracy: 0.8190 - loss: 0.3877\n",
            "Epoch 36/40\n",
            "\u001b[1m197/197\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 37us/step - accuracy: 0.0000e+00 - loss: 0.0000e+00\n",
            "Epoch 37/40\n",
            "\u001b[1m197/197\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m29s\u001b[0m 149ms/step - accuracy: 0.8159 - loss: 0.3872\n",
            "Epoch 38/40\n",
            "\u001b[1m197/197\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 33us/step - accuracy: 0.0000e+00 - loss: 0.0000e+00\n",
            "Epoch 39/40\n",
            "\u001b[1m197/197\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m30s\u001b[0m 149ms/step - accuracy: 0.8233 - loss: 0.3798\n",
            "Epoch 40/40\n",
            "\u001b[1m197/197\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 34us/step - accuracy: 0.0000e+00 - loss: 0.0000e+00\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "loss, accuracy = model_0.evaluate(test_data)\n",
        "print(f\"Loss: {loss:.2f}\")\n",
        "print(f\"Accuracy: {accuracy:.2f}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lu63oyyNKTvC",
        "outputId": "1f5051b9-bc6d-4c24-98c3-d65766bc90b7"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 3s/step - accuracy: 0.6198 - loss: 0.9566\n",
            "Loss: 1.00\n",
            "Accuracy: 0.63\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Get the predicted probabilities for the test set\n",
        "y_pred_probs = model_0.predict(test_data)\n",
        "\n",
        "# Convert probabilities to binary predictions (0 or 1)\n",
        "y_pred = (y_pred_probs > 0.5).astype(int)\n",
        "\n",
        "# Get the true labels for the test set\n",
        "y_true = np.concatenate([y for x, y in test_data], axis=0)\n",
        "\n",
        "# Calculate precision\n",
        "from sklearn.metrics import precision_score\n",
        "precision = precision_score(y_true, y_pred)\n",
        "print(\"Precision:\", precision)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1QGn4LEwKXDA",
        "outputId": "de1aa869-b10e-4733-bc60-271e48ea3fc4"
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 311ms/step\n",
            "Precision: 0.7796610169491526\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.metrics import recall_score\n",
        "\n",
        "# Calculate recall\n",
        "recall = recall_score(y_true, y_pred)\n",
        "print(\"Recall:\", recall)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BSyQMty4KYvo",
        "outputId": "75fc20e8-552c-4ac0-dd50-f861a4e73ae9"
      },
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Recall: 0.8214285714285714\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "from sklearn.metrics import f1_score\n",
        "# Calculate F1-score\n",
        "f1 = f1_score(y_true, y_pred)\n",
        "print(\"F1-score:\", f1)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Rvr4lKQgKaU5",
        "outputId": "864d92f7-9da5-447f-cb41-62702e10f386"
      },
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "F1-score: 0.8\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "ePnSZ0ktKb45"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}